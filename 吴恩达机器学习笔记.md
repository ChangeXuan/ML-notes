- m用来表示训练的样本数量
- n用来表示特征数量
- x表示输入的变量
- y表示输出的变量
- (x,y)表示一个训练样本
- (x^(i),y^(j))表示某个训练样本
- h为一个假设，表示某个函数，用来让x到y的映射输出
- 代价函数是假设与输出样本之间的误差
- 梯度下降是为了能够找出代价函数最小的位置，既代价函数中的局部最小值
- 代价函数是由多个微分组成
- 在计算方程时，可以利用矩阵计算来优化
- 可以使用特征缩放来解决某些范围值过大的特征值
- 可以使用正规方程来直接求出最小值
- 梯度下降的特点1.需要选择合适的学习速率。2.需要多次迭代。3.当特征很多时使用梯度下降很有效。
- 正规方程的特点1.不需要设置学习速率。2.不需要迭代。3.在特征较多的时候会不太适用。
- 当特征值太多时，线性回归和逻辑回归都有可能出现过拟合的现象。
- 解决过拟合的方法1.尽量减少选取的变量的数量。2.使用正则化，既加入正则化来对目标函数进行惩罚。
